{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1F1CV3p4aca7IGy_dLEoYBFuQD2ar8xNv",
      "authorship_tag": "ABX9TyO4jo7flisufxIYnuAlvNg9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeepgundeboina/LearningSpark/blob/main/SparkJobs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "T_CEktWhCj7n",
        "outputId": "2d9745c4-2b08-4026-c849-1678881c1e5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7cf62a98d310>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://dd26321ac9ac:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>SparkJobs</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('SparkJobs').getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "marks=spark.read.format('csv').load('/content/drive/MyDrive/Abc/postgreSQL/students.csv')\n",
        "marks.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvQm269XEHY4",
        "outputId": "a7c2bcc7-84ed-492c-8f41-d96c9565f673"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+----------------+-----+----------+------+\n",
            "|       _c0|          _c1|             _c2|  _c3|       _c4|   _c5|\n",
            "+----------+-------------+----------------+-----+----------+------+\n",
            "|Student ID| Student Name|         Subject|Marks|Attendance|Status|\n",
            "|       101|Anjali Sharma|     Mathematics|   85|        92|  Pass|\n",
            "|       101|Anjali Sharma|         Science|   78|        88|  Pass|\n",
            "|       101|Anjali Sharma|         English|   92|        95|  Pass|\n",
            "|       101|Anjali Sharma|         History|   65|        80|  Pass|\n",
            "|       101|Anjali Sharma|Computer Science|   88|        94|  Pass|\n",
            "|       102| Vikram Singh|     Mathematics|   55|        85|  Pass|\n",
            "|       102| Vikram Singh|         Science|   45|        78|  Pass|\n",
            "|       102| Vikram Singh|         English|   60|        82|  Pass|\n",
            "|       102| Vikram Singh|         History|   35|        70|  Fail|\n",
            "|       102| Vikram Singh|Computer Science|   72|        89|  Pass|\n",
            "|       103|  Priya Patel|     Mathematics|   95|        98|  Pass|\n",
            "|       103|  Priya Patel|         Science|   89|        96|  Pass|\n",
            "|       103|  Priya Patel|         English|   97|        99|  Pass|\n",
            "|       103|  Priya Patel|         History|   82|        91|  Pass|\n",
            "|       103|  Priya Patel|Computer Science|   94|        97|  Pass|\n",
            "|       104|  Rahul Kumar|     Mathematics|   30|        65|  Fail|\n",
            "|       104|  Rahul Kumar|         Science|   42|        79|  Pass|\n",
            "|       104|  Rahul Kumar|         English|   58|        81|  Pass|\n",
            "|       104|  Rahul Kumar|         History|   48|        76|  Pass|\n",
            "+----------+-------------+----------------+-----+----------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the provided code:\n",
        "\n",
        "1.  `spark.read.format('csv').load('/content/drive/MyDrive/Abc/postgreSQL/students.csv')` is a set of transformations to read the data. It does not trigger a job immediately.\n",
        "2.  `marks.show()` is an action that triggers the computation of the data and displays the first few rows.\n",
        "\n",
        "Therefore, only **one** Spark job will be generated by this code snippet."
      ],
      "metadata": {
        "id": "Uf3sVZzfFa7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "marks.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BDuQD0GM_n9",
        "outputId": "ef4047bc-ca0b-403a-ae91-ff385ecb1f61"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "Relation [_c0#139,_c1#140,_c2#141,_c3#142,_c4#143,_c5#144] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string\n",
            "Relation [_c0#139,_c1#140,_c2#141,_c3#142,_c4#143,_c5#144] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Relation [_c0#139,_c1#140,_c2#141,_c3#142,_c4#143,_c5#144] csv\n",
            "\n",
            "== Physical Plan ==\n",
            "FileScan csv [_c0#139,_c1#140,_c2#141,_c3#142,_c4#143,_c5#144] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/drive/MyDrive/Abc/postgreSQL/students.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<_c0:string,_c1:string,_c2:string,_c3:string,_c4:string,_c5:string>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "marks_schema=spark.read.format('csv').option('inferSchema',True).option('header',True).load('/content/drive/MyDrive/Abc/postgreSQL/students.csv')\n",
        "marks_schema.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YULOvGTxNJ67",
        "outputId": "108ae0cc-a470-483c-8a62-1a33b2cebd35"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+----------------+-----+----------+------+\n",
            "|Student ID| Student Name|         Subject|Marks|Attendance|Status|\n",
            "+----------+-------------+----------------+-----+----------+------+\n",
            "|       101|Anjali Sharma|     Mathematics|   85|        92|  Pass|\n",
            "|       101|Anjali Sharma|         Science|   78|        88|  Pass|\n",
            "|       101|Anjali Sharma|         English|   92|        95|  Pass|\n",
            "|       101|Anjali Sharma|         History|   65|        80|  Pass|\n",
            "|       101|Anjali Sharma|Computer Science|   88|        94|  Pass|\n",
            "|       102| Vikram Singh|     Mathematics|   55|        85|  Pass|\n",
            "|       102| Vikram Singh|         Science|   45|        78|  Pass|\n",
            "|       102| Vikram Singh|         English|   60|        82|  Pass|\n",
            "|       102| Vikram Singh|         History|   35|        70|  Fail|\n",
            "|       102| Vikram Singh|Computer Science|   72|        89|  Pass|\n",
            "|       103|  Priya Patel|     Mathematics|   95|        98|  Pass|\n",
            "|       103|  Priya Patel|         Science|   89|        96|  Pass|\n",
            "|       103|  Priya Patel|         English|   97|        99|  Pass|\n",
            "|       103|  Priya Patel|         History|   82|        91|  Pass|\n",
            "|       103|  Priya Patel|Computer Science|   94|        97|  Pass|\n",
            "|       104|  Rahul Kumar|     Mathematics|   30|        65|  Fail|\n",
            "|       104|  Rahul Kumar|         Science|   42|        79|  Pass|\n",
            "|       104|  Rahul Kumar|         English|   58|        81|  Pass|\n",
            "|       104|  Rahul Kumar|         History|   48|        76|  Pass|\n",
            "|       104|  Rahul Kumar|Computer Science|   39|        74|  Fail|\n",
            "+----------+-------------+----------------+-----+----------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One job will be created when `marks_schema` is loaded with `option('inferSchema',True)` because Spark needs to read the data to determine the schema.\n",
        "second job is created when the action show() is called."
      ],
      "metadata": {
        "id": "3xerl5rZOWkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**END OF CODE**"
      ],
      "metadata": {
        "id": "GL6k4NBQOmn2"
      }
    }
  ]
}