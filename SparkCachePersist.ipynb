{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqYG4YdjxjNQYnBYSKyY2V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeepgundeboina/LearningSpark/blob/main/SparkCachePersist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5r63qvzQF8eJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "2b26580a-c791-4d40-fb3d-0c383206d3df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x78a9d2456910>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://8ba8bbd35b65:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>SparkCachePersist</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('SparkCachePersist').getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Adding Colors to dataframe in pandas"
      ],
      "metadata": {
        "id": "pYgVDtqfBx66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def color_df(val):\n",
        "    color='red' if val<0 else 'green'\n",
        "    return 'color:%s' %color\n",
        "df=pd.DataFrame(dict(a=[1,-20,3],b=[-1,2,-34],c=[100,20,-3]))\n",
        "df.style.map(color_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "lcuWHkfF1NFn",
        "outputId": "855c495c-7daf-4bcf-ec44-f6cefc3791ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x78a9b7fa0590>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_8c894_row0_col0, #T_8c894_row0_col2, #T_8c894_row1_col1, #T_8c894_row1_col2, #T_8c894_row2_col0 {\n",
              "  color: green;\n",
              "}\n",
              "#T_8c894_row0_col1, #T_8c894_row1_col0, #T_8c894_row2_col1, #T_8c894_row2_col2 {\n",
              "  color: red;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_8c894\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_8c894_level0_col0\" class=\"col_heading level0 col0\" >a</th>\n",
              "      <th id=\"T_8c894_level0_col1\" class=\"col_heading level0 col1\" >b</th>\n",
              "      <th id=\"T_8c894_level0_col2\" class=\"col_heading level0 col2\" >c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_8c894_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_8c894_row0_col0\" class=\"data row0 col0\" >1</td>\n",
              "      <td id=\"T_8c894_row0_col1\" class=\"data row0 col1\" >-1</td>\n",
              "      <td id=\"T_8c894_row0_col2\" class=\"data row0 col2\" >100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_8c894_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_8c894_row1_col0\" class=\"data row1 col0\" >-20</td>\n",
              "      <td id=\"T_8c894_row1_col1\" class=\"data row1 col1\" >2</td>\n",
              "      <td id=\"T_8c894_row1_col2\" class=\"data row1 col2\" >20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_8c894_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_8c894_row2_col0\" class=\"data row2 col0\" >3</td>\n",
              "      <td id=\"T_8c894_row2_col1\" class=\"data row2 col1\" >-34</td>\n",
              "      <td id=\"T_8c894_row2_col2\" class=\"data row2 col2\" >-3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "data=[('Ram',2339943,'24-03-2022','04-03-1998',40000,'A'),\n",
        "      ('Raju',244335,'04-06-2021','22-08-1994',20000,'A'),\n",
        "      ('Charan',254335,'29-03-2024','11-07-1996',25000,'A'),\n",
        "      ('Devdas',12343,'21-01-2021','04-05-1993',55000,'R'),\n",
        "      ('Rezza',124335,'15-08-2024','03-12-1994',65000,'A')\n",
        "      ]\n",
        "schema=['Name','Emp_id','Joining_date','DOB','Salary','Status']\n",
        "schem1=StructType([\n",
        "    StructField('Name',StringType()),\n",
        "    StructField('Emp_id',IntegerType()),\n",
        "    StructField('Joining_date',DateType()),\n",
        "    StructField('DOB',DateType()),\n",
        "    StructField('Salary',IntegerType()),\n",
        "    StructField('Status',StringType())\n",
        "])\n",
        "df=spark.createDataFrame(data=data,schema=schema)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UlUXVQgBYhV",
        "outputId": "f6ea3c8f-b4a2-4265-d90a-fad782870ee0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------------+----------+------+------+\n",
            "|  Name| Emp_id|Joining_date|       DOB|Salary|Status|\n",
            "+------+-------+------------+----------+------+------+\n",
            "|   Ram|2339943|  24-03-2022|04-03-1998| 40000|     A|\n",
            "|  Raju| 244335|  04-06-2021|22-08-1994| 20000|     A|\n",
            "|Charan| 254335|  29-03-2024|11-07-1996| 25000|     A|\n",
            "|Devdas|  12343|  21-01-2021|04-05-1993| 55000|     R|\n",
            "| Rezza| 124335|  15-08-2024|03-12-1994| 65000|     A|\n",
            "+------+-------+------------+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Transformations"
      ],
      "metadata": {
        "id": "YrUa7fjo_x3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "df=df.withColumn('DOB',to_date(df.DOB,'dd-MM-yyyy'))\n",
        "df=df.withColumn('Joining_date',to_date(df.Joining_date,'dd-MM-yyyy'))\n",
        "df1=df.filter(df.Status=='A')\n",
        "df2=df1.withColumn('Bonus',df1.Salary*0.2)\n",
        "# Use the year() function to extract the year from the DOB column\n",
        "df3=df2.withColumn('Age',year(current_date())-year(df2.DOB))\n",
        "df4=df2.withColumn('YOE',year(current_date())-year(df2.Joining_date))"
      ],
      "metadata": {
        "id": "3-VX1pDV9ju6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Actions"
      ],
      "metadata": {
        "id": "PjdvErUB_1gG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDfBr3yI-Og1",
        "outputId": "5439e22d-7e7b-4376-d050-203030885f22"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------------+----------+------+------+-------+---+\n",
            "|  Name| Emp_id|Joining_date|       DOB|Salary|Status|  Bonus|Age|\n",
            "+------+-------+------------+----------+------+------+-------+---+\n",
            "|   Ram|2339943|  2022-03-24|1998-03-04| 40000|     A| 8000.0| 27|\n",
            "|  Raju| 244335|  2021-06-04|1994-08-22| 20000|     A| 4000.0| 31|\n",
            "|Charan| 254335|  2024-03-29|1996-07-11| 25000|     A| 5000.0| 29|\n",
            "| Rezza| 124335|  2024-08-15|1994-12-03| 65000|     A|13000.0| 31|\n",
            "+------+-------+------------+----------+------+------+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE__ApJa_3_h",
        "outputId": "5c42fb46-6038-43c8-da78-8b2ea58b9153"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------------+----------+------+------+-------+---+\n",
            "|  Name| Emp_id|Joining_date|       DOB|Salary|Status|  Bonus|YOE|\n",
            "+------+-------+------------+----------+------+------+-------+---+\n",
            "|   Ram|2339943|  2022-03-24|1998-03-04| 40000|     A| 8000.0|  3|\n",
            "|  Raju| 244335|  2021-06-04|1994-08-22| 20000|     A| 4000.0|  4|\n",
            "|Charan| 254335|  2024-03-29|1996-07-11| 25000|     A| 5000.0|  1|\n",
            "| Rezza| 124335|  2024-08-15|1994-12-03| 65000|     A|13000.0|  1|\n",
            "+------+-------+------------+----------+------+------+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6B9NREf_6Fg",
        "outputId": "52a326e3-9765-4b0b-c114-2417de2abae1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------------+----------+------+------+-------+\n",
            "|  Name| Emp_id|Joining_date|       DOB|Salary|Status|  Bonus|\n",
            "+------+-------+------------+----------+------+------+-------+\n",
            "|   Ram|2339943|  2022-03-24|1998-03-04| 40000|     A| 8000.0|\n",
            "|  Raju| 244335|  2021-06-04|1994-08-22| 20000|     A| 4000.0|\n",
            "|Charan| 254335|  2024-03-29|1996-07-11| 25000|     A| 5000.0|\n",
            "| Rezza| 124335|  2024-08-15|1994-12-03| 65000|     A|13000.0|\n",
            "+------+-------+------------+----------+------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   As Spark uses Lazy transformations, it first creates a logic to perform the transformation and stores it, and runs the process only after an action is called upon.\n",
        "*   So, when we try to do many transformations based on one like above, df2 is the main transformation, that would be required for all other transformations df3,df4. so in this case any action called up on df2, it has to run all previous transformations and would result in more consumption of computing power, in such cases Persisit and Cache are used.\n",
        "*   In genral, cache is performed in many DB's for optimisation.\n",
        "* In case of Spark, Cache stores data in memory node.\n",
        "\n"
      ],
      "metadata": {
        "id": "YB06HLbe_95N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVYPEMuX_8rl",
        "outputId": "f12fea19-34f5-4a68-df53-641963acfe89"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, Emp_id: bigint, Joining_date: date, DOB: date, Salary: bigint, Status: string, Bonus: double]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU0U1n6vRgfv",
        "outputId": "15927372-c240-440f-a7ab-e8eba6c8ed6e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------------+----------+------+------+-------+---+\n",
            "|  Name| Emp_id|Joining_date|       DOB|Salary|Status|  Bonus|Age|\n",
            "+------+-------+------------+----------+------+------+-------+---+\n",
            "|   Ram|2339943|  2022-03-24|1998-03-04| 40000|     A| 8000.0| 27|\n",
            "|  Raju| 244335|  2021-06-04|1994-08-22| 20000|     A| 4000.0| 31|\n",
            "|Charan| 254335|  2024-03-29|1996-07-11| 25000|     A| 5000.0| 29|\n",
            "| Rezza| 124335|  2024-08-15|1994-12-03| 65000|     A|13000.0| 31|\n",
            "+------+-------+------------+----------+------+------+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJHaByQTRlt-",
        "outputId": "a2f8388f-e317-4ddd-d785-ddb3ad1fef59"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------------+----------+------+------+-------+---+\n",
            "|  Name| Emp_id|Joining_date|       DOB|Salary|Status|  Bonus|YOE|\n",
            "+------+-------+------------+----------+------+------+-------+---+\n",
            "|   Ram|2339943|  2022-03-24|1998-03-04| 40000|     A| 8000.0|  3|\n",
            "|  Raju| 244335|  2021-06-04|1994-08-22| 20000|     A| 4000.0|  4|\n",
            "|Charan| 254335|  2024-03-29|1996-07-11| 25000|     A| 5000.0|  1|\n",
            "| Rezza| 124335|  2024-08-15|1994-12-03| 65000|     A|13000.0|  1|\n",
            "+------+-------+------------+----------+------+------+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df5=df2.withColumn('Bonus',df2.Salary*0.1)\n",
        "df5.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bfr3tsgRoAV",
        "outputId": "e8964635-75af-4e09-b1fb-68cb854c3816"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------------+----------+------+------+------+\n",
            "|  Name| Emp_id|Joining_date|       DOB|Salary|Status| Bonus|\n",
            "+------+-------+------------+----------+------+------+------+\n",
            "|   Ram|2339943|  2022-03-24|1998-03-04| 40000|     A|4000.0|\n",
            "|  Raju| 244335|  2021-06-04|1994-08-22| 20000|     A|2000.0|\n",
            "|Charan| 254335|  2024-03-29|1996-07-11| 25000|     A|2500.0|\n",
            "| Rezza| 124335|  2024-08-15|1994-12-03| 65000|     A|6500.0|\n",
            "+------+-------+------------+----------+------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* After df2 is cached, we could see significant increase in the process of output when action is called."
      ],
      "metadata": {
        "id": "QKxIb0--SLBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Persist is another progammaticaly saving data on Memory or disk or on Both.\n",
        "* there are different type of storing using different storage level\n",
        "* Memory_only, Memory_and_disk, memory_and_disk_deser,Disk_only (read https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.StorageLevel.html for more)\n"
      ],
      "metadata": {
        "id": "6AXK_ABKSq0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark import StorageLevel\n",
        "df2.persist(StorageLevel.MEMORY_ONLY)\n",
        "df3.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjkWxxmMR4h0",
        "outputId": "4aa69d75-eec6-4734-871a-ad5e7cf61252"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------------+----------+------+------+-------+---+\n",
            "|  Name| Emp_id|Joining_date|       DOB|Salary|Status|  Bonus|Age|\n",
            "+------+-------+------------+----------+------+------+-------+---+\n",
            "|   Ram|2339943|  2022-03-24|1998-03-04| 40000|     A| 8000.0| 27|\n",
            "|  Raju| 244335|  2021-06-04|1994-08-22| 20000|     A| 4000.0| 31|\n",
            "|Charan| 254335|  2024-03-29|1996-07-11| 25000|     A| 5000.0| 29|\n",
            "| Rezza| 124335|  2024-08-15|1994-12-03| 65000|     A|13000.0| 31|\n",
            "+------+-------+------------+----------+------+------+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VH_jS60VSnV1"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}