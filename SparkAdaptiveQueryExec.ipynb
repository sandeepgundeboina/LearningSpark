{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbKZtP5vY5cSI4YikpeaPY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeepgundeboina/LearningSpark/blob/main/SparkAdaptiveQueryExec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLXbJiAzAkqF",
        "outputId": "840b4d17-b0b3-4350-aeab-d4e0a28bd17c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('SparkAQE').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Ugfsu1TsAowP",
        "outputId": "c160bd34-5204-4b7e-8e1a-5b0f6b8f343c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ef2e016d810>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://5420bfc64546:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>SparkAQE</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transactions=[\n",
        "    (4, 'Apples', 1.03),\n",
        "    (3, 'Apples', 2.68),\n",
        "    (4, 'Oranges', 4.72),\n",
        "    (1, 'Apples', 1.94),\n",
        "    (3, 'Bread', 3.07),\n",
        "    (1, 'Apples', 0.75),\n",
        "    (4, 'Bananas', 4.71),\n",
        "    (2, 'Bread', 2.86),\n",
        "    (3, 'Bread', 2.61),\n",
        "    (3, 'Apples', 0.64),\n",
        "    (1, 'Oranges', 1.60),\n",
        "    (1, 'Bread', 1.50)\n",
        "]\n",
        "\n",
        "schema=['store_id', 'product', 'price']\n",
        "df1=spark.createDataFrame(data=transactions, schema=schema)\n",
        "df1.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbzwMnD6Au88",
        "outputId": "c98526c0-595f-47ee-e8fb-a09cab4d2873"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+-----+\n",
            "|store_id|product|price|\n",
            "+--------+-------+-----+\n",
            "|       4| Apples| 1.03|\n",
            "|       3| Apples| 2.68|\n",
            "|       4|Oranges| 4.72|\n",
            "|       1| Apples| 1.94|\n",
            "|       3|  Bread| 3.07|\n",
            "|       1| Apples| 0.75|\n",
            "|       4|Bananas| 4.71|\n",
            "|       2|  Bread| 2.86|\n",
            "|       3|  Bread| 2.61|\n",
            "|       3| Apples| 0.64|\n",
            "|       1|Oranges|  1.6|\n",
            "|       1|  Bread|  1.5|\n",
            "+--------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "store=[\n",
        "    (1, \"New York\"),\n",
        "    (2, \"Los Angeles\"),\n",
        "    (3, \"Chicago\"),\n",
        "    (4, \"Houston\")\n",
        "]\n",
        "schema1=['store_id', 'store_name']\n",
        "df2=spark.createDataFrame(data=store, schema=schema1)\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkahPl_wBDWU",
        "outputId": "76177e08-dc4b-4736-8b33-5a00a6f5d375"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+\n",
            "|store_id| store_name|\n",
            "+--------+-----------+\n",
            "|       1|   New York|\n",
            "|       2|Los Angeles|\n",
            "|       3|    Chicago|\n",
            "|       4|    Houston|\n",
            "+--------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With AQE disabled"
      ],
      "metadata": {
        "id": "EadtKDo0FotL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.conf.set(\"spark.sql.adaptive.enabled\", \"False\")"
      ],
      "metadata": {
        "id": "iCPYho1PEdob"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3=df1.join(df2, on='Store_id', how='inner')\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmZP7zQWBFt1",
        "outputId": "46ff48c1-a5fd-465b-cd20-fe03fe229437"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+-----+-----------+\n",
            "|store_id|product|price| store_name|\n",
            "+--------+-------+-----+-----------+\n",
            "|       1| Apples| 1.94|   New York|\n",
            "|       1| Apples| 0.75|   New York|\n",
            "|       1|Oranges|  1.6|   New York|\n",
            "|       1|  Bread|  1.5|   New York|\n",
            "|       3| Apples| 2.68|    Chicago|\n",
            "|       3|  Bread| 3.07|    Chicago|\n",
            "|       3|  Bread| 2.61|    Chicago|\n",
            "|       3| Apples| 0.64|    Chicago|\n",
            "|       2|  Bread| 2.86|Los Angeles|\n",
            "|       4| Apples| 1.03|    Houston|\n",
            "|       4|Oranges| 4.72|    Houston|\n",
            "|       4|Bananas| 4.71|    Houston|\n",
            "+--------+-------+-----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I71dSJw-CfZT",
        "outputId": "92737255-dd25-496e-86ae-7c19f164bacc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(5) Project [store_id#0L, product#1, price#2, store_name#20]\n",
            "+- *(5) SortMergeJoin [store_id#0L], [store_id#19L], Inner\n",
            "   :- *(2) Sort [store_id#0L ASC NULLS FIRST], false, 0\n",
            "   :  +- Exchange hashpartitioning(store_id#0L, 200), ENSURE_REQUIREMENTS, [plan_id=117]\n",
            "   :     +- *(1) Filter isnotnull(store_id#0L)\n",
            "   :        +- *(1) Scan ExistingRDD[store_id#0L,product#1,price#2]\n",
            "   +- *(4) Sort [store_id#19L ASC NULLS FIRST], false, 0\n",
            "      +- Exchange hashpartitioning(store_id#19L, 200), ENSURE_REQUIREMENTS, [plan_id=123]\n",
            "         +- *(3) Filter isnotnull(store_id#19L)\n",
            "            +- *(3) Scan ExistingRDD[store_id#19L,store_name#20]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With AQE enabled"
      ],
      "metadata": {
        "id": "TIP6u1M3Ft2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
        "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")"
      ],
      "metadata": {
        "id": "bDdXmVZwD6BA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4=df1.join(df2, on='store_id', how='inner')\n",
        "df4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSootyewEH3o",
        "outputId": "4f58a1be-5acf-4548-ae98-175543206d6c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+-----+-----------+\n",
            "|store_id|product|price| store_name|\n",
            "+--------+-------+-----+-----------+\n",
            "|       1| Apples| 1.94|   New York|\n",
            "|       1| Apples| 0.75|   New York|\n",
            "|       1|Oranges|  1.6|   New York|\n",
            "|       1|  Bread|  1.5|   New York|\n",
            "|       2|  Bread| 2.86|Los Angeles|\n",
            "|       3| Apples| 2.68|    Chicago|\n",
            "|       3|  Bread| 3.07|    Chicago|\n",
            "|       3|  Bread| 2.61|    Chicago|\n",
            "|       3| Apples| 0.64|    Chicago|\n",
            "|       4| Apples| 1.03|    Houston|\n",
            "|       4|Oranges| 4.72|    Houston|\n",
            "|       4|Bananas| 4.71|    Houston|\n",
            "+--------+-------+-----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4.explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnXCbOSlESET",
        "outputId": "e1da2712-e8cd-456e-bc69-c84642255e5c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [store_id#0L, product#1, price#2, store_name#20]\n",
            "   +- SortMergeJoin [store_id#0L], [store_id#19L], Inner\n",
            "      :- Sort [store_id#0L ASC NULLS FIRST], false, 0\n",
            "      :  +- Exchange hashpartitioning(store_id#0L, 200), ENSURE_REQUIREMENTS, [plan_id=283]\n",
            "      :     +- Filter isnotnull(store_id#0L)\n",
            "      :        +- Scan ExistingRDD[store_id#0L,product#1,price#2]\n",
            "      +- Sort [store_id#19L ASC NULLS FIRST], false, 0\n",
            "         +- Exchange hashpartitioning(store_id#19L, 200), ENSURE_REQUIREMENTS, [plan_id=284]\n",
            "            +- Filter isnotnull(store_id#19L)\n",
            "               +- Scan ExistingRDD[store_id#19L,store_name#20]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this Case, there might not be a major difference, but when there are 2 large dataframe joined, or a query is executed, there a difference can be seen in  shuffling parameters, while joining the type of join used, within the spark app."
      ],
      "metadata": {
        "id": "4LbR9DwkFwss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**END OF CODE**"
      ],
      "metadata": {
        "id": "khN5hnsuGggh"
      }
    }
  ]
}